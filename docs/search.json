[
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Presidential Fellow Human Complexity Lab Department of Anthropology The Ohio State University scaggs.32@osu.edu\n\n\n\n\nHuman Subsistence \\(\\times\\) Cooperation \\(\\times\\) Community and Landscape Ecology \\(\\times\\) Computational Social Science \\(\\times\\) Complex Systems \\(\\times\\) Network Science\n\n\n\n\n\n\n\n\n\nYear\nInstitution\nProgram\nDegree\n\n\n\n\n2021\nOhio State University\nAnthropology\nPhD candidate\n\n\n2018\nOregon State University\nApplied Anthropology\nMaster of Science\n\n\n2016\nBoise State University\nAnthropology\nBachelor of Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nCitation\n\n\n\n\n2023\nRoss, C. T., Hooper, P., Smith, J. E., [and 101 others, including Scaggs, S., A.] (2023) Reproductive Inequality in Humans and Other Mammals. Proceedings of the National Academy of Sciences, 120(22), e2220124120. https://doi.org/10.1073/pnas.2220124120\n\n\n2023\nDowney, S. S., Walker, M., Moschler, J., Penados, F., Peterman, W., Rongjun, Q., Scaggs, S. A., Song, S. (2023). An intermediate level of disturbance with customary agricultural practices increases species diversity in Maya community forests in Belize. Nature Communications, Earth, and Environment. https://doi.org/10.1038/s43247-023-01089-6\n\n\n2022\nPiperata, B., Scaggs, S., Dufour, D., Adams, I. (2022) Measuring food security: An introduction to tools for human biologists and ecologists. American Journal of Human Biology. https://doi.org/10.1002/ajhb.23821\n\n\n2021\nScaggs, S., Gerkey, D., McLaughlin, K. (2021). Linking subsistence harvest diversity and productivity to adaptive capacity in an Alaskan food sharing network. American Journal of Human Biology. Special Issue: Anthropological Insights on Adaptation and Climate Change, Vol. 33 (4): e23573. https://doi.org/10.1002/ajhb.23573\n\n\n2021\nKawa, N., Arceno, M. A., Goeckner, R., Hunter, C., Rhue, S., Scaggs, S., Biwer, M., Downey, S., Field, J., Gremillion, K., McCorriston, J., Willow, A., Newton, E., Moritz, M. (2021). Training Wicked Scientists for a World of Wicked Problems. Humanities & Social Sciences Communications. Vol. 8 (189). https://doi.org/10.1057/s41599-021-00871-1\n\n\n2020\nDowney, S., Gerkey, D., Scaggs, S. (2020). The Milpa Game: a field experiment investigating the social and ecological dynamics of Q'eqchi' Maya swidden agriculture. Human Ecology, Vol. 48: 423-438. https://doi.org/10.1007/s10745-020-00169-x\n\n\n2020\nMoritz, M., Scaggs, S., Shapiro, C., Hinkelman, S. (2020). Comparative Study of Territoriality across Forager Societies. Human Ecology, Vol. 48: 225-234. https://doi.org/10.1007/s10745-020-00141-9\n\n\n2019\nSnopkowski, K., Demps, K., Scaggs, S., Griffiths, R., Fulk, K., May, S., Neagle, K., Downs, K., Eugster, M., Amend, T., Heath, J. (2019). Small Group Learning is Associated with Reduced Salivary Cortisol and Testosterone in Undergraduate Students. Journal of the Scholarship of Teaching and Learning, Vol. 19 (5): 36-52. https://doi.org/10.14434/josotl.v19i5.24230.\n\n\n2017\nScaggs, S. A., Fulk, K., Glass, D. J., Ziker, J. P. (2017) Framing charitable solicitation in a behavioral experiment: Cues derived from evolutionary theory of cooperation and anthropological economics. In Li, M., Tracer, D. P. (eds.) Interdisciplinary Perspectives on Fairness, Equity, and Justice, 153-178. Springer. https://doi.org/10.1007/978-3-319-58993-0_10\n\n\n\n\n\n\n\n\n\n\n\n\nContribution matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nTitle\nFunding Agency\nAmount\n\n\n\n\n2024\nPresidential Fellowship\nThe Ohio State University\n\n\n\n2021\nDoctoral Dissertation Research Improvement Grant (DDRIG)\nCultural Anthropology Program, National Science Foundation\n$20,000\n\n\n2019\nDaniel T. Hughes Memorial Fund\nDepartment of Anthropology, The Ohio State University\n$300\n\n\n2019\nPre-Dissertation Field Research Grant\nTinker Foundation, College of Latin American Studies, The Ohio State University\n$1,750\n\n\n2018\nGraduate Research Fellowship (GRF)\nGraduate Research Fellowship Program, National Science Foundation\n\n\n\n2018\nGraduate Research and Writing Residency\nSpring Creek Project, Oregon State University\n$250\n\n\n2015\nSpecial Undergraduate Recognition Award\nEvolutionary Anthropology Society, American Anthropology Association\n$250\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nTitle\nMeeting\nType\n\n\n\n\n2024\nIntermediate-scale disturbance increases forest diversity in Maya community forests\n84th Society for Applied Anthropology\nPodium\n\n\n2023\nHuman Influences on Central American Food Webs\n83rd Society for Applied Anthropology\nPodium\n\n\n2021\nThe Importance of Humans in Neotropical Food Webs\nFall Forum 2021, Translational Data Analytics Institute\nPoster\n\n\n2021\nSubsistence harvest diversity, social networks, and adaptive capacity to environmental change in Alaska.\n90th American Association of Physical Anthropologists\nInvited Symposium\n\n\n2019\nPlaying 'The Milpa Game': Using field experiments to investigate common pool resource dilemmas in Toledo District, Belize\n118th American Anthropological Association\nPodium\n\n\n2018\nSubsistence harvest productivity and biodiversity in Alaskan social networks\n117th American Anthropological Association\nPodium\n\n\n2018\nExponential random graph modeling of productivity, diversity, and reciprocity in Alaskan food sharing networks\n5th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2017\nDynamic Change, Social Networks, and Harvests: Levels of Resilience in Alaska\n29th Human Behavior and Evolution Society\nPoster\n\n\n2017\nStress: The effects of social and solitary learning on salivary hormones\n29th Human Behavior and Evolution Society\nPoster\n\n\n2016\nThe Solicitation of Charitable Donations: Experimental Evidence from Behavioral Economic Games\nBoise State University Undergraduate Research Conference\nPodium\n\n\n2016\nUnderstanding Charitable Donations\nBoise State University Advancement Team\nInvited Talk\n\n\n2016\nEndocrine stress response in college students to solitary and group learning\n4th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2016\nFour Pathways to Generosity\n4th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2015\nFour Pathways to Generosity: Evolutionary Mechanisms Differentially Affect Charitable Donations\n114th American Anthropological Association\nPodium"
  },
  {
    "objectID": "CV.html#shane-a.-scaggs",
    "href": "CV.html#shane-a.-scaggs",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Presidential Fellow Human Complexity Lab Department of Anthropology The Ohio State University scaggs.32@osu.edu\n\n\n\n\nHuman Subsistence \\(\\times\\) Cooperation \\(\\times\\) Community and Landscape Ecology \\(\\times\\) Computational Social Science \\(\\times\\) Complex Systems \\(\\times\\) Network Science\n\n\n\n\n\n\n\n\n\nYear\nInstitution\nProgram\nDegree\n\n\n\n\n2021\nOhio State University\nAnthropology\nPhD candidate\n\n\n2018\nOregon State University\nApplied Anthropology\nMaster of Science\n\n\n2016\nBoise State University\nAnthropology\nBachelor of Science\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nCitation\n\n\n\n\n2023\nRoss, C. T., Hooper, P., Smith, J. E., [and 101 others, including Scaggs, S., A.] (2023) Reproductive Inequality in Humans and Other Mammals. Proceedings of the National Academy of Sciences, 120(22), e2220124120. https://doi.org/10.1073/pnas.2220124120\n\n\n2023\nDowney, S. S., Walker, M., Moschler, J., Penados, F., Peterman, W., Rongjun, Q., Scaggs, S. A., Song, S. (2023). An intermediate level of disturbance with customary agricultural practices increases species diversity in Maya community forests in Belize. Nature Communications, Earth, and Environment. https://doi.org/10.1038/s43247-023-01089-6\n\n\n2022\nPiperata, B., Scaggs, S., Dufour, D., Adams, I. (2022) Measuring food security: An introduction to tools for human biologists and ecologists. American Journal of Human Biology. https://doi.org/10.1002/ajhb.23821\n\n\n2021\nScaggs, S., Gerkey, D., McLaughlin, K. (2021). Linking subsistence harvest diversity and productivity to adaptive capacity in an Alaskan food sharing network. American Journal of Human Biology. Special Issue: Anthropological Insights on Adaptation and Climate Change, Vol. 33 (4): e23573. https://doi.org/10.1002/ajhb.23573\n\n\n2021\nKawa, N., Arceno, M. A., Goeckner, R., Hunter, C., Rhue, S., Scaggs, S., Biwer, M., Downey, S., Field, J., Gremillion, K., McCorriston, J., Willow, A., Newton, E., Moritz, M. (2021). Training Wicked Scientists for a World of Wicked Problems. Humanities & Social Sciences Communications. Vol. 8 (189). https://doi.org/10.1057/s41599-021-00871-1\n\n\n2020\nDowney, S., Gerkey, D., Scaggs, S. (2020). The Milpa Game: a field experiment investigating the social and ecological dynamics of Q'eqchi' Maya swidden agriculture. Human Ecology, Vol. 48: 423-438. https://doi.org/10.1007/s10745-020-00169-x\n\n\n2020\nMoritz, M., Scaggs, S., Shapiro, C., Hinkelman, S. (2020). Comparative Study of Territoriality across Forager Societies. Human Ecology, Vol. 48: 225-234. https://doi.org/10.1007/s10745-020-00141-9\n\n\n2019\nSnopkowski, K., Demps, K., Scaggs, S., Griffiths, R., Fulk, K., May, S., Neagle, K., Downs, K., Eugster, M., Amend, T., Heath, J. (2019). Small Group Learning is Associated with Reduced Salivary Cortisol and Testosterone in Undergraduate Students. Journal of the Scholarship of Teaching and Learning, Vol. 19 (5): 36-52. https://doi.org/10.14434/josotl.v19i5.24230.\n\n\n2017\nScaggs, S. A., Fulk, K., Glass, D. J., Ziker, J. P. (2017) Framing charitable solicitation in a behavioral experiment: Cues derived from evolutionary theory of cooperation and anthropological economics. In Li, M., Tracer, D. P. (eds.) Interdisciplinary Perspectives on Fairness, Equity, and Justice, 153-178. Springer. https://doi.org/10.1007/978-3-319-58993-0_10\n\n\n\n\n\n\n\n\n\n\n\n\nContribution matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nTitle\nFunding Agency\nAmount\n\n\n\n\n2024\nPresidential Fellowship\nThe Ohio State University\n\n\n\n2021\nDoctoral Dissertation Research Improvement Grant (DDRIG)\nCultural Anthropology Program, National Science Foundation\n$20,000\n\n\n2019\nDaniel T. Hughes Memorial Fund\nDepartment of Anthropology, The Ohio State University\n$300\n\n\n2019\nPre-Dissertation Field Research Grant\nTinker Foundation, College of Latin American Studies, The Ohio State University\n$1,750\n\n\n2018\nGraduate Research Fellowship (GRF)\nGraduate Research Fellowship Program, National Science Foundation\n\n\n\n2018\nGraduate Research and Writing Residency\nSpring Creek Project, Oregon State University\n$250\n\n\n2015\nSpecial Undergraduate Recognition Award\nEvolutionary Anthropology Society, American Anthropology Association\n$250\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nTitle\nMeeting\nType\n\n\n\n\n2024\nIntermediate-scale disturbance increases forest diversity in Maya community forests\n84th Society for Applied Anthropology\nPodium\n\n\n2023\nHuman Influences on Central American Food Webs\n83rd Society for Applied Anthropology\nPodium\n\n\n2021\nThe Importance of Humans in Neotropical Food Webs\nFall Forum 2021, Translational Data Analytics Institute\nPoster\n\n\n2021\nSubsistence harvest diversity, social networks, and adaptive capacity to environmental change in Alaska.\n90th American Association of Physical Anthropologists\nInvited Symposium\n\n\n2019\nPlaying 'The Milpa Game': Using field experiments to investigate common pool resource dilemmas in Toledo District, Belize\n118th American Anthropological Association\nPodium\n\n\n2018\nSubsistence harvest productivity and biodiversity in Alaskan social networks\n117th American Anthropological Association\nPodium\n\n\n2018\nExponential random graph modeling of productivity, diversity, and reciprocity in Alaskan food sharing networks\n5th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2017\nDynamic Change, Social Networks, and Harvests: Levels of Resilience in Alaska\n29th Human Behavior and Evolution Society\nPoster\n\n\n2017\nStress: The effects of social and solitary learning on salivary hormones\n29th Human Behavior and Evolution Society\nPoster\n\n\n2016\nThe Solicitation of Charitable Donations: Experimental Evidence from Behavioral Economic Games\nBoise State University Undergraduate Research Conference\nPodium\n\n\n2016\nUnderstanding Charitable Donations\nBoise State University Advancement Team\nInvited Talk\n\n\n2016\nEndocrine stress response in college students to solitary and group learning\n4th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2016\nFour Pathways to Generosity\n4th Northwest Evolution, Ecology, and Human Behavior Symposium\nPoster\n\n\n2015\nFour Pathways to Generosity: Evolutionary Mechanisms Differentially Affect Charitable Donations\n114th American Anthropological Association\nPodium"
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Data Visualization Gallery",
    "section": "",
    "text": "Three decades of Saguaro cactus surveys at Saguaro National Park. Top: a lollipop graph showing the research effort put into surveyed Saguaro. Bottom: annual growth in inches for all saguaro surveyed and the average growth trend from 1980 to 2010. Data from Orum, Ferguson, & Mihail (2016). “Saguaro (Carnegiea gigantea) Mortality and Population Regeneration in the Cactus Forest of Saguaro National Park: Seventy-Five Years and Counting”. PLOS One. https://doi.org/10.1371/journal.pone.0160899"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Hello. My name is Shane Scaggs. I am a Presidential Fellow in the Human Complexity Lab in the Department of Anthropology at The Ohio State University. My research combines approaches from anthropology, ecology, and data science to understand the how humans, wildlife, and plants interact, and the complex patterns that emerge from these interactions."
  },
  {
    "objectID": "posts/2021-12-22-network-size-and-structure/index.html",
    "href": "posts/2021-12-22-network-size-and-structure/index.html",
    "title": "Network size and structure",
    "section": "",
    "text": "This post is also available on the Social Ecological Networks Group.\nThe size of a network is determined by the number of vertices and edges within it, and different size networks have different structural properties. This is obviously true if social processes like homophily, preferential attachment, or triadic closure influence network size, but it is also true for randomly generated networks.\nHow do properties like density, sparseness, degree distribution, or connectivity change as the number of vertices in a network increases? To find out, I set up a few computational experiments for directed and undirected networks."
  },
  {
    "objectID": "posts/2021-12-22-network-size-and-structure/index.html#degree-distribution",
    "href": "posts/2021-12-22-network-size-and-structure/index.html#degree-distribution",
    "title": "Network size and structure",
    "section": "Degree distribution",
    "text": "Degree distribution\nFor a network of any size, as the edge density increases, the degree distribution is expected to become more uniform, with the mean degree starting to approximate \\(n\\). To see how degree distribution changes with edge density, we can calculate degree for each node across a variety of density levels. Here I do this for networks with 10, 75, and 150 vertices, each ranging in density from 0.01 to 0.99.\n\nd &lt;- seq(0.01,0.99, length.out=11)\nl &lt;- list()\nfor(i in seq_along(d)) {\n  l[[i]] &lt;- network(10, directed = F, density = d[i])\n  m &lt;- data.frame(lapply(l, degree))\n}\ncolnames(m) &lt;- paste0('Density',d)\nhead(m)\n\n  Density0.01 Density0.108 Density0.206 Density0.304 Density0.402 Density0.5\n1           0            0            6            8            8          8\n2           0            2            0            6            8          8\n3           0            0            6            8            6         10\n4           0            2            2            8           10         16\n5           0            2            4           10            6         10\n6           0            2            2            4            8          8\n  Density0.598 Density0.696 Density0.794 Density0.892 Density0.99\n1            8           14           16           14          18\n2           14           10           18           16          18\n3           12           14           18           18          18\n4           14           10           16           14          18\n5            8           12           16           16          18\n6           10           14           14           18          18\n\n\nI do this for each network size and then plot the distributions to compare.\n\n\n\n\n\nA comparison of the degree distributions at increasing levels of density for three different size networks.\n\n\n\n\nThe degree distributions of networks that have only a couple hundred vertices or less can overlap quite a bit across different levels of edge density. Large networks have a much more precise degree distribution. This makes it clear why descriptive statistics that depend on density cannot easily be compared between different networks, unless the networks are large.\n\nAverage Path Length\nThe length of a path between two vertices is determined by the number of vertices that lie between them. A direct path between two vertices is equal to 1.\nWe observed that as \\(m\\) increases, mean degree approaches \\(n\\). We can expect that when mean degree is approximately \\(n\\), the average path length should be approximately 1.\nThe function below accepts a sequence of densities and a number of vertices, and returns the mean degree and average path length at each level of density.\n\nl &lt;- list()\napl &lt;- c()\n\nDegApl &lt;- function(n, directed = F, d, seed=777) {\n  for(i in seq_along(d)) {\n    l[[i]] &lt;- network(n, directed = directed, \n                      density = d[i], seed=seed)\n    m &lt;- data.frame(lapply(l, degree))\n    k &lt;- lapply(l, geodist, inf.replace = 0, count.paths = F)\n    apl[i] &lt;- mean(k[[i]]$gdist)\n  }\n  remove(l,k) \n  colnames(m) &lt;- c(1:length(d))\n  mD &lt;- apply(m, 2, mean)\n  return(cbind(apl,mD,n,d))\n}\n\nNow we can explore relationships between these variables by running this function on networks with different sizes. Here we use a long sequence of densities to better approximate relationships.\nWe can expect that mean degree and density are positively correlated. But what is the shape of this relationship?\n\n\n\n\n\nThe association between edge density and mean degree is approximately linear.\n\n\n\n\nAverage path length should also systematically vary with density, but it is unclear what the shape of this relationship will look like. For instance, at low density, many paths = 0 because many vertices are isolated. However, dense networks should have short paths, as most vertices are directly connected to each other.\n\n\n\n\n\nExplosive percolation of average path length\n\n\n\n\nAt very low density (0.01), the average path length is essentially 0, but just a small increase in density leads to explosive increase in the average path length. This phenomenon is an example of explosive percolation, and it occurs because even randomly added edges have a chance of connecting isolated vertices to a large component.\nThis explosion happens even sooner for networks with a greater number of vertices. Exactly when does this percolation happen? At the sparsepoint (!) which we know varies systematically as a function of \\(n\\). Because the density at which a network goes from being sparse to not sparse decreases as a function of network size, we see explosive changes in average path length sooner and sooner as network size increases.\nAs we continue to increase density, the average path length decreases because the number of direct paths between vertices that are part of the largest component continues to increase, and this drives down the average path length. Eventually the average path length for networks of all sizes converges on 1."
  },
  {
    "objectID": "posts/2023-2-10-using-simulation-to-understand-glm-part1/index.html",
    "href": "posts/2023-2-10-using-simulation-to-understand-glm-part1/index.html",
    "title": "Gaussian models, Part I",
    "section": "",
    "text": "Prologue\nConventional statistics courses that I’ve taken in the past have been incredibly unsatisfying. The material was dry and technical and this made only a very small portion of the content seem all that practical.\nI believe the essential problem with most conventional statistics courses is that they tend to emphasize statistical theory over statistical practice. This makes doing statistics feel very static, despite the reality that data analysis is a dynamic, iterative process.\nFast forward to 2023 and I’m having students and colleagues ask me modeling questions that they clearly didn’t have answered in their analytical training. They want to know which “test” to run and which buttons to click. Each conversation I have like this gives more motivation to help researchers shift from testing to modeling.\nThe goal of this post is to start developing some primers for statistical models. Each post in this series will use simulation to understand a different model family in generalized linear modeling.\n\n\nBackground\nWhether I’m working on Bayesian or frequentist models, the analytical workflow that I use today is based on the free lectures provided by Richard McElreath based on his book Statistical Rethinking. They are fantastic and mind opening.\n\n\nGetting started\nLet’s begin by just thinking about the mechanics of a linear model. First let’s look at the equation for such a model:\n\\[Y_i = \\beta_0 + \\beta_1 X_i\\] This equation looks more formidable than it is. The placeholders \\(X_i\\) and \\(Y_i\\) represent variables. These are values that we will include in the model from our data. The little \\(i\\) is an index; you can sort of think of it like row \\(i\\). When you are viewing an equation, you can look for these indices to determine which parameters of the equation are likely to vary.\nThe greek letters are parameters that we estimate. In this case, \\(\\beta_0\\) is an intercept parameter – the expected mean value when \\(X_i\\) is 0. You’ll also see this parameter symbolized with the greek letter \\(\\alpha\\). The \\(\\beta_1\\) parameter is a slope, a scalar that influences the relationship between \\(X_i\\) and \\(Y_i\\).\n\n\nSimulating variables\nWe won’t be working with data at the moment. Instead we will simulate. So let’s start with \\(X\\). Let’s imagine we have a variable with a mean value of 10 and a standard deviation of 2.\n\nN = 400\nx = rnorm( n=N, mean=10, sd=2 )\n\nHaving generated this variable x using random numbers from a Gaussian distribution, we get something similar to a bell shaped curve.\n\n\n\n\n\nNow let’s do the same for \\(Y\\), using a mean of 7 and a standard deviation of 1.5.\n\ny = rnorm( n=N, mean=7, sd=1.5 )\n\nNow what happens if we plot the association between these two variables?\n\n\n\n\n\nBecause both x and y were generated independent of each other, there is no discernible relationship between them. This implies that the estimated value of \\(\\beta_1\\) will be near 0. We can confirm this with a model.\n\nd = data.frame(x,y)\nmodel1 = glm( formula = y ~ x, data=d, family = gaussian ) \nsummary(model1)\n\n\nCall:\nglm(formula = y ~ x, family = gaussian, data = d)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.60297    0.36661   18.01   &lt;2e-16 ***\nx            0.04311    0.03623    1.19    0.235    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.011392)\n\n    Null deviance: 803.38  on 399  degrees of freedom\nResidual deviance: 800.53  on 398  degrees of freedom\nAIC: 1418.7\n\nNumber of Fisher Scoring iterations: 2\n\n\nIndeed, the coefficient esimate for x – the slope – is just about 0. And because the relationship is pretty much non-existent, the intercept parameter \\(\\beta_0\\) is estimated to be approximately the mean value for y.\n\n\nForm a relationship\nSo how would we go about linking x and y? Well we need to provide value for the slope parameter. I find this a bit easier to think about if we write a function.\n\nlinear = function( x, b0, b1 ) {\n    y = b0 + b1*x\n    data.frame(x,y)\n}\n\nNow suppose we want there to be a negative relationship between x and y. We need to provide a negative value for b1.\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5 )\n\nNotice that we dont actually provide a vector of Y values this time. This is because they are generated by the function, rather than by sampling from a Gaussian distribution.\nLet’s plot these results and see what we find.\n\n\n\n\n\nSo we have enforced a perfect linear relationship between x and y. But wouldn’t we have expected a bit more variation rather than a perfect line? Indeed, in a sense we have lost the sd = 1.5 that we originally included when we generated y the first time. To include it, we need a different equation.\n\\[Y_i = \\beta_0 + \\beta_1 X_i + e_i\\] This term \\(e_i\\) is an “error” term. It is the residual deviance that is left unexplained by the other parameters in the equation.\nLet’s think about this another way. The original mean and sd used in y = rnorm(N, 7, 1.5) has been moved to the \\(\\beta_0\\) and the \\(e_i\\). We no longer supply the mean, but instead we estimated it as \\(\\beta_0\\) with some residual error, \\(e_i\\) left over.\nLet’s amend our function.\n\nlinear = function( x, b0, b1, e ) {\n    y = b0 + b1*x + e\n    data.frame(x,y)\n}\n\nNow let’s supply a constant value for e in this function; how about 1.5 like we used before?\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5, e = 2 )\n\n\n\n\n\n\nThat didn’t really work did it. Why not? Well if we look a bit closer, we see that all that has happened is the value 1.5, which we supplied for e, was just added on at the end. This is effectively like setting b0 to 8.5 instead of 7. What we really need is a distribution of error, centered on 0 and deviating by 1.5.\n\nx = rnorm( n=N, mean=10, sd=2 )\ne = rnorm( n=N, mean=0, sd=1.5 )\nsim1 = linear( x=x, b0 = 7, b1 = -1.5, e=e )\n\n\n\n\n\n\nThat looks a bit more like what we might expect. But if it really is true that we’re just adding some error onto the end, then we could get the same result if we don’t use e at all and instead supply our original y generated with rnorm in place of b0.\nSet e to 0 and supply a distribution of values for b0.\n\nx = rnorm( n=N, mean=10, sd=2 )\nsim1 = linear( x=x, b0 = rnorm( n=N, mean=7, sd=1.5), b1 = -1.5, e=0 )\n\n\n\n\n\n\nIn future example, we might return to this approach as a way to created random intercepts. Right now, this just shows that the generative process will work the same with either approach. However, in practice, it will still be useful to use e to think about error.\n\n\nFit the model again\nNow that we have out generated data set, let’s try rerunning the glm from above.\n\nmodel1 = glm( formula = y ~ x, data=sim1, family = gaussian ) \nsummary(model1)\n\n\nCall:\nglm(formula = y ~ x, family = gaussian, data = sim1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.37888    0.41167   17.92   &lt;2e-16 ***\nx           -1.52464    0.03965  -38.46   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2.223387)\n\n    Null deviance: 4172.91  on 399  degrees of freedom\nResidual deviance:  884.91  on 398  degrees of freedom\nAIC: 1458.8\n\nNumber of Fisher Scoring iterations: 2\n\n\nThis time, we recover our slope parameter \\(\\beta_1\\) and we more accurately recover our intercept parameter \\(\\beta_0\\).\n\n\nPower\nThe power of this technique is in our ability to run multiple simulation with different values. Let’s try this with different values for b1.\n\nx = rnorm( n=N, mean=10, sd=2 )\ne = rnorm( n=N, mean=0, sd=1.5 )\nb1 = seq( from=-3, to=3, length=12 )\n\nL = list()\nfor( i in seq_along(b1) ) {\n    out = linear( x=x, b0 = 7, b1 = b1[i], e=e )\n    out$b1 = round(b1[i], 2)\n    L[[i]] = out\n}\n\nIn the code above, I’ve done many of the same things that I did above. The only difference is that I have create a vector of b1 values ranging from -3 to +3, and I’ve looped over these values, plugging in each element of the vector b1 into the linear equation.\nI stored all my results in a list. Each element of the list is a data frame containing the values of x, y, along with the value of b1. Let’s look at one of them.\n\nhead(L[[1]])\n\n          x         y b1\n1  9.398208 -24.44265 -3\n2  8.971316 -20.72967 -3\n3 10.411001 -24.99041 -3\n4  6.384421 -12.79901 -3\n5  9.752267 -22.44014 -3\n6 10.367787 -24.17492 -3\n\n\nNow if we used the bind_rows function from {dplyr}, we can change this list into a long form data frame where our results are grouped by the iteration. This will enable some fancy plotting.\n\nldf = bind_rows(L)\n\nNow let’s look at every relationship. This time I’ll show the plotting code so you can see how it’s done.\n\nggplot( data=ldf, aes(x=x, y=y) ) + ptheme + \n    geom_point( stroke=2, size=1, pch=21, color='#ff110011') + \n    facet_wrap(~b1, nrow = 4)\n\n\n\n\nWe can immediately see how change the values of b1 has altered the relationship.\nNow let’s do one more version of this, but instead, we will loop through different values of e, creating more or less error, while holding b1 constant.\n\nx = rnorm( n=N, mean=10, sd=2 )\ne = seq( from=0.1, to=5, length=12)\n\nL = list()\nfor( i in seq_along(e) ) {\n    out = linear( x=x, b0 = 7, b1 = 2, e= rnorm(n=N, mean=0, sd = e[i]) )\n    out$e = round(e[i], 2)\n    L[[i]] = out\n}\nldf = bind_rows(L)\nggplot( data=ldf, aes(x=x, y=y) ) + ptheme + \n    geom_point( stroke=2, size=1, pch=21, color='#ff110033') + \n    facet_wrap(~e, nrow = 4)\n\n\n\n\nNow we see how changing the value e greatly increased the level of deviance for each of these simulated relationships."
  },
  {
    "objectID": "posts/2023-2-28-food-web/index.html",
    "href": "posts/2023-2-28-food-web/index.html",
    "title": "Let’s make some food webs",
    "section": "",
    "text": "Food webs are representations of the feeding relationships between plants, animals, and other organisms in an ecosystem. Ecologists will often use network graphs and network analysis to describe and analyze these feeding relationships. A major goal of theoretical ecology is coming up with models that can be used describe empirical food webs. A good place to start this process is by simulating feeding relationships. Network science and computation can help us do this.\nIn this post, I develop a simulation of a food web based on body size and dietary strategy. My goal is to understand some of the structural implications that arise from these two drivers. This is a work in progress."
  },
  {
    "objectID": "posts/2023-2-28-food-web/index.html#species-attributes",
    "href": "posts/2023-2-28-food-web/index.html#species-attributes",
    "title": "Let’s make some food webs",
    "section": "Species attributes",
    "text": "Species attributes\nThe first thing I’m going to do is generate some species attributes. These attributes includes things we might measure about species (e.g., body size) and categories we might place different species in (e.g., trophic level).\nFirst, I’ll imagine I have 25 species from four different trophic levels: carnivore, omnivore, herbivore, and autotroph.\n\nset.seed(777)\nN = 25\ntrophs = c('carn','omni','herb','auto')\n\nI can sample with replacement from a vector of these trophic levels to assign each species to one of them. If I use the default prob in the sample function, each level is sampled with equal probability. This is something I might want to change to reflect empirical food webs. For example, there tend to be a lot of plants and carnivores, and relatively fewer omnivores and herbivores.\n\n\n\n\n\nNext, I need to assign each species a body size. This is somewhat awkward to do for plants (autotrophs), so for simplicity, I’ll assume that plant body size refers to the total edible biomass of that particular plant, on average.\nSince body sizes are always positive, continuous values, I’ll use a gamma distribution.\n\nbody_size = rgamma(N, shape = 2)\n\n\n\n\n\n\nSo I have many species that are pretty small and some a bit larger. The units here are pretty arbitrary here but maybe I can think of them as hundreds of pounds?\nNow I can store all of these in a data frame.\n\nd = data.frame(\n    species = 1:N, \n    troph = sample( trophs, size = N, replace = TRUE, prob =  c(0.3,0.1,0.1,0.5) ), \n    body_size = rgamma(N, shape = 2)\n)\nhead(d)\n\n  species troph body_size\n1       1  auto 4.5290711\n2       2  auto 0.5468126\n3       3  carn 0.9878395\n4       4  auto 1.5093469\n5       5  auto 3.0427018\n6       6  carn 1.4672133"
  },
  {
    "objectID": "posts/2023-2-28-food-web/index.html#feeding-relationships-as-dyads",
    "href": "posts/2023-2-28-food-web/index.html#feeding-relationships-as-dyads",
    "title": "Let’s make some food webs",
    "section": "Feeding relationships as dyads",
    "text": "Feeding relationships as dyads\nThe object of analysis in a food web is not the individual species – it is the relationships between them. So I’ll need to create a dyadic dataset. There are many simple ways to do this but I will do it in a slightly more complicated way so that the structure of the dataset is tidy.\nI begin by creating a grid of every pair of species.\n\ng = expand.grid(1:N, 1:N)\nhead(g)\n\n  Var1 Var2\n1    1    1\n2    2    1\n3    3    1\n4    4    1\n5    5    1\n6    6    1\n\n\nNext I merge this grid twice with the individual attributes using first and second columns as primary keys to link the grid with the data frame.\n\ng = merge(g, d, by.x = 'Var1', by.y = 'species')\ng = merge(g, d, by.x = 'Var2', by.y = 'species')\nhead(g)\n\n  Var2 Var1 troph.x body_size.x troph.y body_size.y\n1    1    1    auto    4.529071    auto    4.529071\n2    1   15    carn    2.457736    auto    4.529071\n3    1   20    auto    2.457149    auto    4.529071\n4    1   22    carn    1.393432    auto    4.529071\n5    1   25    auto    0.524775    auto    4.529071\n6    1    6    carn    1.467213    auto    4.529071\n\n\nThe result is a bit messy, so I’ll do some rename and reordering to clean it up.\n\ncolnames(g) = c('prey','pred','troph_pred','body_size_pred', 'troph_prey', 'body_size_prey')\n\n# tidy it up \ng = g %&gt;% \n    arrange(pred,prey) %&gt;%\n    mutate(dyad = 1:nrow(g)) %&gt;%\n    select(pred, prey, dyad, troph_pred, troph_prey, body_size_pred, body_size_prey) \nhead(g)\n\n  pred prey dyad troph_pred troph_prey body_size_pred body_size_prey\n1    1    1    1       auto       auto       4.529071      4.5290711\n2    1    2    2       auto       auto       4.529071      0.5468126\n3    1    3    3       auto       carn       4.529071      0.9878395\n4    1    4    4       auto       auto       4.529071      1.5093469\n5    1    5    5       auto       auto       4.529071      3.0427018\n6    1    6    6       auto       carn       4.529071      1.4672133\n\n\nI’ve given an id to every dyad and I’ve tagged the predators and prey in each dyad. Thus you can read the original grid as column 1 eats column 2.\nNow I want to create some additional variables. The first is the difference between the body size of the predator and prey.\n\n# calculate body size differences \ng$body_size_diff = (g$body_size_pred - g$body_size_prey)+0.1 \n\nI add 0.1 to the difference so that dyads which are the same species do not zero out. This is a little bit hacky but it is necessary for steps I’ll take later on.\nThe other variables will index specific types of feed interactions. These are carnivory, omnivory, and herbivory. Although I know what the trophic level of each species is, I want to tag specific instances of these dietary strategies which helps me deal with the constraints each species has. For example, plants don’t eat any species, while carnivores can only each omnivores or herbivores. This is a way of specifying which feeding relationships are actually possible.\n\n# carnivores \ng$carnivory = ifelse(g$troph_pred == 'carn' & !g$troph_prey == 'auto', 1, 0)\n\n# omnivores \ng$omnivory = ifelse(g$troph_pred == 'omni' , 1, 0)\n\n# herbivory \ng$herbivory = ifelse(g$troph_pred == 'herb' & g$troph_prey == 'auto'  , 1, 0)\n\nThe final data frame looks something like this.\n\nhead(g)\n\n  pred prey dyad troph_pred troph_prey body_size_pred body_size_prey\n1    1    1    1       auto       auto       4.529071      4.5290711\n2    1    2    2       auto       auto       4.529071      0.5468126\n3    1    3    3       auto       carn       4.529071      0.9878395\n4    1    4    4       auto       auto       4.529071      1.5093469\n5    1    5    5       auto       auto       4.529071      3.0427018\n6    1    6    6       auto       carn       4.529071      1.4672133\n  body_size_diff carnivory omnivory herbivory\n1       0.100000         0        0         0\n2       4.082258         0        0         0\n3       3.641232         0        0         0\n4       3.119724         0        0         0\n5       1.586369         0        0         0\n6       3.161858         0        0         0"
  },
  {
    "objectID": "posts/2023-2-28-food-web/index.html#models",
    "href": "posts/2023-2-28-food-web/index.html#models",
    "title": "Let’s make some food webs",
    "section": "Models",
    "text": "Models\nWe’re almost ready to simulate. Before we do, I’ll talk a little bit about the two models I’m going to use.\n\nA simple allometric model\nThe allometric model basically says that species will feed according to their body size. This implies that the probability of a feed relationship between any two species scales with body size. Here I am using a power function accomplish this:\n\\(p_{ij} = D_{ij}^\\alpha\\)\nThis says that the probability between any two species \\(ij\\) is a function the difference between those two species (\\(D_{ij}\\)) raised to the power \\(\\alpha\\). But if I run this as is…\n\na = 1.15\nD = g$body_size_diff\np = sign(D)*abs(D)^a\n\n# look at first 10 values\np[1:10]\n\n [1] 0.07079458 5.04121914 4.42013512 3.70027192 1.70006271 3.75780028\n [7] 4.20830669 4.93041051 2.59683707 0.10331906\n\n\nThere is a weird trick in here (sign(D)*abs(D)^alpha) because R will spit out some NaN values when we take a value to a non-integer power. See the discussion of this here.\nThere is one problem with the values of p though; they are not probabilities. So we will need to convert them to probabilities using a logit link transformation. So the actual equation looks like this:\n\\(p_{ij} = logistic(D_{ij}^\\alpha)\\)\n\n# link functions \nlogit = function(p) {  log( p / (1 - p))  }\ninv_logit = function(x) { 1 / (1+ exp(-x) ) }\n\na = 1.15\nD = g$body_size_diff\np = inv_logit( sign(D)*abs(D)^a )\n\n# look at first 10 values\np[1:10]\n\n [1] 0.5176913 0.9935757 0.9881105 0.9758794 0.8455429 0.9771971 0.9853464\n [8] 0.9928283 0.9306577 0.5258068\n\n\nThat looks a bit better.\n\n\nDietary model\nThe other model uses the index variables for feeding strategies to determine the probability of a link. This model essentially says that the probability of any given link is determined by the rate at which that feeding strategies occurs.\n\\(p_{ij} = logistic( \\beta_{C}C + \\beta_{O}O + \\beta_{H}H)\\)\nWe set that rate using beta coefficients on each of the index variables. Since any particular link can only be 1 strategy, the other strategies zero out of the equation.\n\nbC = 0.5\nbO = 0.5\nbH = 0.5\np = inv_logit( bC*g$carnivory + bO*g$omnivory + bC*g$omnivory )\n\nIn practice, we might set specific rates for specific pairs of species, or give each species an offset. In this case, we just have a constant probability for each type of interaction."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nGaussian models, Part I\n\n\nUsing simulation to understand generalized linear models\n\n\n\n\nmodeling\n\n\nGLM\n\n\nsimulation\n\n\nstatistics\n\n\nbeginner\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2023\n\n\nShane A. Scaggs\n\n\n\n\n\n\n  \n\n\n\n\nLet’s make some food webs\n\n\nLearning to simulate food webs\n\n\n\n\necology\n\n\nstructure\n\n\nsimulation\n\n\nfood webs\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nShane A. Scaggs\n\n\n\n\n\n\n  \n\n\n\n\nNetwork size and structure\n\n\n\n\n\n\n\ntheory\n\n\nstructure\n\n\nsimulation\n\n\nscale\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2021\n\n\nShane A. Scaggs\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html#project-2",
    "href": "projects.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2"
  },
  {
    "objectID": "projects.html#project-3",
    "href": "projects.html#project-3",
    "title": "Projects",
    "section": "Project 3",
    "text": "Project 3"
  }
]