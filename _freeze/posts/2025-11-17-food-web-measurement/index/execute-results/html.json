{
  "hash": "da0560243f0362115a2a3bdbbe927284",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Food Web Generation and Measurement\"\ndate: 2025-11-17\ncategories: [community ecology, food webs, networks]\nformat:\n  html:\n    toc: true\nbibliography: 2025-11-18.bib\n---\n\n### Introduction\n\nFood webs are often represented as network graphs, where nodes represent species and links represent observed feeding interactions, or potential feeding interactions inferred from species traits. The [Web of Life](https://www.web-of-life.es/) database houses many such graphs, showcasing their interesting structural patterns and the tremendous efforts ecologists have gone to in order to collect these challenging data.  \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![An example food web originally published by @bascompte2005interaction.](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\nA particular challenge when collecting food web data is knowing whether sampling effort is sufficient. This is particular relevant when studying networks because if even a single rare species goes unobserved, it can impact the overall network structure. Since many theories of food webs focus directly on explaining the structure of food webs, measurement models are needed that can help us infer whether the observed structure results from fundamental processes of community assembly or from partial sampling. In this blog post, we explore this measurement problem and develop some preliminary simulations and validations. \n\nTo begin, let's lay out a basic model. Let's assume that we want to infer species interactions using a hierarchical model (multiple food webs). This let's us pool information from across multiple webs to understand our ability to detect trophic links. \n\nFor each food web $k = 1,...,K$, we observe pairs of species interactions $A^{\\text{obs}}_{ij,k} \\in \\{0,1\\}$. A value of $1$ indicates the presence of a link between $i \\rightarrow j$. Given this, we model the probability of a link $p_{ij,k}$ as\n\n$$\n\\begin{equation}\n\\text{logit}(p_{ij,k}) = \\alpha_k + u_{i,k} + v_{j,k}\n\\end{equation}\n$$\n\nwhere $\\alpha_k$ is a baseline interaction rate for web $k$, and $u_{i,k}$ and $v_{j,k}$ are consumer- and resource-specific random effects. We could then say that the \"true\" set of interactions is Bernoulli distributed \n\n$$\n\\begin{equation}\nA^{\\text{obs}}_{ij,k} \\sim \\text{Bernoulli}(p_{ij,k})\n\\end{equation}\n$$\nIn other words, there is a probability $p_{ij,k}$ that we observe a link between $ij$ in food web $k$. Such a probability could be directly computed from $A$. But if sampling is biased, then this probability will inherit this bias. For this reason, we also need a detection model. \n\n$$\n\\begin{equation}\n\\text{logit}(\\phi_k) = \\mu_p + \\delta_{p,k}\n\\end{equation}\n$$\n\nWe assume that each web has its own rate of detection $\\phi_k$. The parameter $\\mu_k$ is the average log-odds of detection across all food webs, and $\\delta_{p,k}$ is a specific deviation of web $k$ from the global average, which we model as non-centered: $\\delta_{\\phi,k} \\sim \\mathcal{N}(0,\\sigma^2_{\\phi})$. \n\n\nIt follows that the probability of observing a link is \n\n$$\n\\begin{equation}\nq_{ij,k} = \\phi_k \\cdot p_{ij,k}\n\\end{equation}\n$$\nWe use this to amend our original likelihood to\n\n$$\n\\begin{equation}\nA^{\\text{obs}}_{ij,k} \\sim \\text{Bernoulli}(q_{ij,k})\n\\end{equation}\n$$\n\nIn essence, this model assumes that\n\n- If $A^{\\text{true}}_{ij,k} = 0$, then $A^{\\text{obs}}_{ij,k} = 0$. \n- If $A^{\\text{true}}_{ij,k} = 1$, then we observe $A^{\\text{obs}}_{ij,k} = 1$ with probability $\\phi_{ij,k}$. \n\nAlthough false positives are also a possible source of bias, we leave this out of the model, for now. \n\nFinally, we need to declare hierarchical, non-centered priors for all parameters, beginning first with the interaction rates, then the detection probabilities, and finally the random effects. We assume a weakly informative $\\mathcal{N}(0,1)$ prior on all latent deviations, and $\\text{Exponential}(1)$ for all SD. \n\n### Interaction rates\n\n$$\n\\begin{align}\n\\alpha_k &= \\mu_{\\alpha} + \\sigma_{\\alpha} \\alpha^{(z)}_k \\qquad &\\text{non-centered} \\\\\n\\alpha^{(z)} &\\sim \\mathcal{N}(0,1) \\qquad &\\text{latent deviation} \\\\ \n\\mu_{\\alpha} &\\sim \\mathcal{N}(0,1) \\qquad &\\text{global mean interaction rate} \\\\ \n\\sigma_{\\alpha} &\\sim \\text{Exponential}(1) \\qquad &\\text{global interaction SD}\n\\end{align}\n$$\n\n### Detection \n\n$$\n\\begin{align}\n\\delta_{\\phi,k} &= \\mu_{\\phi} + \\sigma_{\\phi} \\delta^{(z)}_{\\phi,k} \\qquad &\\text{non-centered} \\\\ \n\\delta^{(z)} &\\sim \\mathcal{N}(0,1) \\qquad &\\text{latent deviation} \\\\ \n\\mu_{\\phi} &\\sim \\mathcal{N}(0,1) \\qquad &\\text{global mean detection rate} \\\\ \n\\sigma_{\\phi} &\\sim \\text{Exponential}(1) \\qquad &\\text{global detection SD}\n\\end{align}\n$$\n\n### Consumer and resource random effects \n\n$$\n\\begin{align}\nu_{i,k} &= \\sigma_u u^{(z)}_{i,k}, \\qquad &u^{(z)}_{i,k} \\sim \\mathcal{N}(0,1) \\\\  \nv_{j,k} &= \\sigma_v v^{(z)}_{j,k}, \\qquad &v^{(z)}_{j,k} \\sim \\mathcal{N}(0,1) \\\\ \n\\sigma_u &\\sim \\text{Exponential}(1) \\qquad &\\sigma_v \\sim \\text{Exponential}(1)\n\\end{align}\n$$\n\n## Simulation \n\nTo test this model, we need to simulate food webs to serve as the \"true\" sets of interactions, and \"observe\" our food webs probabilistically from them. \n\nWe begin by setting up our parameters. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Setup ----\nset.seed(777)\ninv_logit = function(x) exp(x) / (1 + exp(x))\n\n# ---- Parameters ----\nK = 5   \nS = 30\nmu_alpha = -2\nsd_alpha = 1\nsigma_u = 2\nsigma_v = 1\nmu_phi = -1\nsd_phi = 0.5\n\n# generate varying base rates and detection probabilities \nalpha_k = rnorm(K, mu_alpha, sd_alpha); alpha_k\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -1.5102138 -2.3985414 -1.4891637 -2.3988121 -0.3613139\n```\n\n\n:::\n\n```{.r .cell-code}\nphi_k = inv_logit(rnorm(K, mu_phi, sd_phi)); phi_k\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3341748 0.2893284 0.3904238 0.2491572 0.2333515\n```\n\n\n:::\n:::\n\n\nWe then set up some containers for the simulation results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Outputs ----\nA_true_list = list()\nA_obs_list  = list()\n```\n:::\n\n\nThe basic procedure is the following: \n\n- Generate $u_{i,k}$ and $v_{j,k}$.\n- Create $S \\times S$ matrices for the \"true\" and \"observed\" webs.\n- Generate $p_{ij,k}$ based on $\\alpha_k$ + random effects.\n- Adjust observed links based on $\\phi_k \\cdot p_{ij,k}$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(k in 1:K) {\n  \n  # Random effects\n  u_i = rnorm(S, mean = 0, sd = sigma_u)\n  v_j = rnorm(S, mean = 0, sd = sigma_v)\n  \n  # Matrices \n  A_true = matrix(0, ncol = S, nrow = S)\n  A_obs = matrix(0, ncol = S, nrow = S)\n  \n  # Loop \n  for(i in 1:S) for(j in 1:S) {\n    p_ijk = inv_logit(alpha_k[k] + u_i[i] + v_j[j])\n    A_true[i,j] = rbinom(1, 1, p_ijk)\n    A_obs[i,j] = rbinom(1, 1, phi_k[k] * p_ijk)\n    \n  }\n  A_true_list[[k]] = A_true\n  A_obs_list[[k]] = A_obs\n}\n```\n:::\n\n\nThis yields the following summary. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat = data.frame(\n  web = 1:K, \n  true_links = sapply(A_true_list, function(A) sum(A)), \n  observed_links = sapply(A_obs_list, function(A) sum(A)), \n  detection = phi_k, \n  alpha = alpha_k\n); dat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  web true_links observed_links detection      alpha\n1   1        286             89 0.3341748 -1.5102138\n2   2        125             29 0.2893284 -2.3985414\n3   3        216             85 0.3904238 -1.4891637\n4   4        284             69 0.2491572 -2.3988121\n5   5        356             98 0.2333515 -0.3613139\n```\n\n\n:::\n:::\n\n\nIf we examine the degree distributions across all of the webs, we can see how they differ after we adjust for the probability of detection. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndeg = function(A) rowSums(A)\ndata.frame(\n  True = unlist(lapply(A_true_list, deg)),\n  Observed  = unlist(lapply(A_obs_list,  deg))\n) |> \n  gather(key = key, value = degree) |> \n  ggplot(aes(degree)) + \n  geom_histogram(color='white', fill='black') + \n  facet_wrap(~key) + \n  labs(x = 'Outgoing links', y = 'Count')\n```\n\n::: {.cell-output-display}\n![The out-degree distribution across all simulated webs.](index_files/figure-html/unnamed-chunk-7-1.png){width=576}\n:::\n:::\n\n\nWe can see that the degree distribution of the observed links is more zero-inflated and that the tail of the distribution has contracted. Altering the values of $\\sigma_u$ and $\\sigma_v$ can change these properties to some extent, especially the heaviness of the tail. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nA_true = A_true_list[[1]]\nA_obs = A_obs_list[[1]]\n\nrow_sums = rowSums(A_true)\n\nsort_order = order(row_sums)\n\npar(mfrow=c(1,2))\nimage(A_true[sort_order, ], col = c('black','white'), main = 'True', xaxt = 'n', yaxt = 'n')\nimage(A_obs[sort_order, ],  col = c('black','white'), main = 'Observed', xaxt = 'n', yaxt = 'n')\n```\n\n::: {.cell-output-display}\n![Examples of true and observed adjacency matrices.](index_files/figure-html/unnamed-chunk-8-1.png){width=624}\n:::\n:::\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}